model:  # parameters of the mLTM in form of lists. simulator will evaluate their cartesian product
  protocols: ["AND", "OR"]
  mi_values: [0.1, 0.15, 0.2]
  seed_budgets: [10]
  ss_methods: [
    # "btw",
    # "d^btw",
    "g^random",
    "g^d^random",
    # # "cbim",
    # # "d^cbim",
    # # "cim",
    # # "d^cim",
    # "cls",
    # "d^cls",
    # "dcb",
    # "d^dcb",
    # "deg_c",
    # "d^deg_c",
    # "deg_cd",
    # "d^deg_cd",
    # # "k_sh",
    # # "d^k_sh",
    # # "k_sh_m",
    # # "d^k_sh_m",
    # # "kpp_sh",
    # # "d^kpp_sh",
    # # "nghb_1s",
    # # "d^nghb_1s",
    # # "nghb_2s",
    # # "d^nghb_2s",
    # "nghb_sd",
    # "d^nghb_sd",
    # "p_rnk",
    # "d^p_rnk",
    # "p_rnk_m",
    # "d^p_rnk_m",
    # "random",
    # "d^random",
    # "v_rnk",
    # "d^v_rnk",
    # "v_rnk_m",
    # "d^v_rnk_m",
  ]

networks: [
  # "arxiv",
  "aucs",
  # "cannes",
  # "ckm_physicians",
  # "eu_transportation",
  # "eu_transport_klm",
  # "lazega",
  # "er1",
  # "er2",
  # "er3",
  # "er5",
  # "sf1",
  # "sf2",
  # "sf3",
  # "sf5",
  # "timik1q2009",
  "toy_network",
]

ranking_path: null  # path to read rankings of actors from (null to compute them before simulaiton)
# ranking_path: "_example_results/rankings"

run:
  max_epochs_num: -1  # this is a wildcard for unlimited allowed epochs in LTM spread instance
  patience: 1  # after given number of epochs without spreading progress simulation is stopped
  repetitions: 2  # number of repetitions of each simulated case
  random_seed: 43  # seed of the random numbers generator (to make results reproducible)

logging:
  full_output_frequency: -1  # freq. of logging very detailed data form simulated cases
  compress_to_zip: False  # wether compress ot zip "detailed_logs" and "rankings"
  out_dir: "./_example_results"  # directory where to save results
